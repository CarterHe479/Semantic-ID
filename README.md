# Semantic ID Tokenizers for Generative Recommenders

**RQ-KMeans / RQ-VAE / VQ-VAE** çš„ä¸€ä½“åŒ–å®ç°ï¼šå°† item è¿ç»­è¡¨å¾å‹ç¼©ä¸º**ç¦»æ•£è¯­ä¹‰ ID**ï¼Œå¹¶æä¾›å€’æ’æ£€ç´¢ + FAISS é‡æ’ + ç¦»çº¿è¯„æµ‹ç®¡çº¿ã€‚

> å·²åœ¨ Amazon Reviews 2023ï¼ˆæ ·ä¾‹å­é›†ï¼‰ä¸Šæ‰“é€š **Step 4â€“8**ï¼šæ•°æ®é¢„å¤„ç† â†’ åµŒå…¥æŠ½å– â†’ åˆ†è¯å™¨è®­ç»ƒ/ç¼–ç  â†’ è¯­ä¹‰ ID å¯¼å‡º â†’ å€’æ’ç´¢å¼• â†’ FAISS é‡æ’ â†’ è¯„æµ‹ã€‚

---

## âœ¨ ç‰¹æ€§
- **ä¸‰ç§åˆ†è¯å™¨**ï¼š`RQ-KMeans`ï¼ˆæ®‹å·® kmeansï¼‰ã€`RQ-VAE`ï¼ˆEMA ç‰ˆã€K ç»´åˆ†å—è¿‘é‚»ï¼‰ã€`VQ-VAE`ï¼ˆEMA ç‰ˆã€K ç»´åˆ†å—è¿‘é‚»ï¼‰
- **ä½å†…å­˜å®ç°**ï¼šæ‰€æœ‰è·ç¦»è®¡ç®—æ”¯æŒ **K ç»´åˆ†å—** å’Œ **æŒ‰æ‰¹**ï¼Œé¿å…æ„é€  `BÃ—KÃ—d` å·¨çŸ©é˜µ
- **ä¸€é”®è¯„æµ‹**ï¼šå€’æ’å€™é€‰ +ï¼ˆå¯é€‰ï¼‰FAISS é‡æ’ï¼Œè¾“å‡º Recall@K / NDCG@K ç­‰
- **è·¨è®¾å¤‡**ï¼šCPU / macOS MPS / CUDAï¼ˆVAE è®­ç»ƒä¸ç¼–ç å‡å¯ï¼‰

---

## ğŸ“¦ ç›®å½•ç»“æ„ï¼ˆå…³é”®æ–‡ä»¶ï¼‰
src/
data/
preprocess_amazon23.py # Step 4ï¼šæ•°æ®é¢„å¤„ç†ï¼ˆç»Ÿä¸€ schemaï¼‰
models/
RQ_KMeans.py # æ®‹å·® KMeansï¼ˆfit/encode ä½å†…å­˜ï¼‰
RQ_VAE.py # RQ-VAEï¼ˆEMA + åˆ†å—è¿‘é‚» + æ‰¹å†…ç†µï¼‰
VQ_VAE.py # VQ-VAEï¼ˆEMA + åˆ†å—è¿‘é‚»ï¼‰
train/
extract_embeddings.py # Step 5ï¼šæŠ½å– item è¿ç»­è¡¨å¾ï¼ˆBERT/SBERTï¼‰
train_tokenizer.py # Step 7ï¼šè®­ç»ƒ/ç¼–ç ï¼ˆrqkmeans | rqvae | vqvaeï¼‰
export_codes.py # Step 8ï¼šå¯¼å‡ºè¯­ä¹‰ ID è¡¨ï¼ˆparquetï¼‰
retrieval/
build_inverted.py # å€’æ’ç´¢å¼•ï¼ˆcode â†’ item_idsï¼‰
build_faiss.py # å…¨åº“ FAISS ç´¢å¼•ï¼ˆå¯é€‰ï¼‰
eval_offline.py # å€™é€‰ + é‡æ’ + çº¿ä¸‹è¯„æµ‹


---

## ğŸ› ï¸ ç¯å¢ƒå®‰è£…

> **å»ºè®® conda**ï¼ˆè§£å†³ FAISS ä¸ NumPy å…¼å®¹æ€§é—®é¢˜ï¼‰ã€‚macOS / Linux çš†å¯ã€‚

```bash
conda create -n semantic-id python=3.10 -y
conda activate semantic-id

# CPU ç‰ˆ PyTorchï¼ˆmacOS MPS ç”¨ pip å®˜æ–¹è½®å­ä¹Ÿå¯ï¼‰
pip install torch==2.3.1 --extra-index-url https://download.pytorch.org/whl/cpu

# åŸºç¡€ä¾èµ–
pip install "numpy<2" pandas pyarrow scikit-learn tqdm
pip install transformers==4.41.2 datasets==2.21.0

# FAISSï¼ˆå¯é€‰ï¼Œä½†æ¨èï¼›ä¼šè‡ªåŠ¨å¸¦æ¥å…¼å®¹çš„ numpy 1.26.xï¼‰
conda install -c conda-forge "faiss-cpu>=1.7.4,<2.0.0" -y


å¦‚æœä½ æƒ³ç”¨ MPSï¼ˆApple èŠ¯ç‰‡ï¼‰ï¼šæŒ‰ PyTorch å®˜æ–¹æ–‡æ¡£å®‰è£…æ”¯æŒ MPS çš„ torchï¼Œè¿è¡Œè„šæœ¬æ—¶åŠ  --device mpsã€‚

âš¡ å¿«é€Ÿå¼€å§‹
0) æ•°æ®å‡†å¤‡ï¼ˆAmazon Reviews 2023ï¼‰

æŒ‰ src/data/preprocess_amazon23.py å°†æ•°æ®è§„æ•´åˆ°ï¼š

data/amazon23/{train,valid,test}.parquet
# è‡³å°‘åº”åŒ…å«ï¼šuser_id, item_id, timestamp, title, descriptionï¼ˆå…¶ä»–åˆ—å¯ç©ºï¼‰

1) æŠ½å– item è¿ç»­è¡¨å¾ï¼ˆStep 5ï¼‰
# è®­ç»ƒç”¨ï¼ˆå»é‡åæ¯ item ä¸€æ¡ï¼‰
python -m src.train.extract_embeddings \
  --data ./data/amazon23/train.parquet \
  --text-cols title,description \
  --out ./outputs/emb/train_emb.pt

# å…¨é‡ itemsï¼ˆtrain/valid/test åˆå¹¶ï¼‰
python -m src.train.extract_embeddings \
  --data "./data/amazon23/*.parquet" \
  --text-cols title,description \
  --out ./outputs/emb/items_emb.pt

2) åˆ†è¯å™¨è®­ç»ƒä¸ç¼–ç ï¼ˆStep 7ï¼‰

RQ-KMeansï¼ˆå¯ä½œä¸º RQ-VAE åˆå§‹åŒ–ï¼‰

# è®­ç»ƒ
python -m src.train.train_tokenizer --method rqkmeans \
  --in ./outputs/emb/train_emb.pt --out ./outputs/rqkmeans_4x256 \
  --L 4 --K 256 --max-train 200000

# ä»…ç¼–ç å…¨é‡ items
python -m src.train.train_tokenizer --method rqkmeans --no-train \
  --encode ./outputs/emb/items_emb.pt \
  --out    ./outputs/rqkmeans_4x256 \
  --load   ./outputs/rqkmeans_4x256/codebooks.npz


RQ-VAEï¼ˆEMA ç‰ˆï¼›å»ºè®®ç”¨ RQ-KMeans åˆå§‹åŒ–ï¼‰

# è®­ç»ƒ
python -m src.train.train_tokenizer --method rqvae \
  --in ./outputs/emb/train_emb.pt --out ./outputs/rqvae_4x256 \
  --L 4 --K 256 --init ./outputs/rqkmeans_4x256/codebooks.npz \
  --epochs 5 --batch-size 4096 --dist-chunk 1024 --device mps

# ä»…ç¼–ç å…¨é‡ items
python -m src.train.train_tokenizer --method rqvae --no-train \
  --encode ./outputs/emb/items_emb.pt \
  --out   ./outputs/rqvae_4x256 \
  --load  ./outputs/rqvae_4x256/codebooks.npz \
  --encode-batch-size 4096 --device mps


VQ-VAEï¼ˆEMA ç‰ˆï¼‰

# è®­ç»ƒ
python -m src.train.train_tokenizer --method vqvae \
  --in ./outputs/emb/train_emb.pt --out ./outputs/vqvae_4096 \
  --K 4096 --epochs 6 --batch-size 8192 --dist-chunk 512 --device mps

# ä»…ç¼–ç å…¨é‡ items
python -m src.train.train_tokenizer --method vqvae --no-train \
  --encode ./outputs/emb/items_emb.pt \
  --out   ./outputs/vqvae_4096 \
  --load  ./outputs/vqvae_4096/codebooks.npz \
  --encode-batch-size 4096 --device mps

3) å¯¼å‡ºè¯­ä¹‰ ID è¡¨ï¼ˆStep 8ï¼‰
# RQ ç³»ï¼ˆä¼šè¾“å‡º c1..cL + code_strï¼‰
python -m src.train.export_codes \
  --codes ./outputs/rqvae_4x256/codes.npy \
  --ids   ./outputs/emb/items_emb.ids.npy \
  --out   ./outputs/rqvae_4x256/items.parquet --concat-col

# VQ ç³»ï¼ˆè¾“å‡º tokenï¼‰
python -m src.train.export_codes \
  --codes ./outputs/vqvae_4096/codes.npy \
  --ids   ./outputs/emb/items_emb.ids.npy \
  --out   ./outputs/vqvae_4096/items.parquet

4) æ„å»ºå€’æ’ & FAISS ç´¢å¼•ï¼ˆå¯é€‰ï¼‰ & è¯„æµ‹
# å€’æ’ï¼ˆæ¯ç§æ–¹æ³•ä¸€æ¬¡ï¼‰
python -m src.retrieval.build_inverted --items ./outputs/rqkmeans_4x256/items.parquet --outdir ./outputs/rqkmeans_4x256
python -m src.retrieval.build_inverted --items ./outputs/rqvae_4x256/items.parquet   --outdir ./outputs/rqvae_4x256
python -m src.retrieval.build_inverted --items ./outputs/vqvae_4096/items.parquet    --outdir ./outputs/vqvae_4096

# å…¨åº“ FAISSï¼ˆè‹¥ faiss å®‰è£…å¤±è´¥å¯è·³è¿‡ï¼›è¯„æµ‹ä¼šè‡ªåŠ¨å›é€€åˆ°å…¨åº“ç‚¹ç§¯ï¼‰
python -m src.retrieval.build_faiss \
  --emb ./outputs/emb/items_emb.pt \
  --ids ./outputs/emb/items_emb.ids.npy \
  --outdir ./outputs/faiss --normalize

# è¯„æµ‹ï¼ˆä¼šè¾“å‡º ./results/offline_eval.csvï¼‰
python -m src.retrieval.eval_offline \
  --train ./data/amazon23/train.parquet \
  --valid ./data/amazon23/valid.parquet \
  --test  ./data/amazon23/test.parquet \
  --items-emb ./outputs/emb/items_emb.pt \
  --items-ids ./outputs/emb/items_emb.ids.npy \
  --faiss-index ./outputs/faiss/index.faiss \
  --faiss-ids   ./outputs/faiss/ids.npy \
  --methods rqkmeans_4x256 rqvae_4x256 vqvae_4096 \
  --use-faiss-rerank \
  --max-test 5000 \
  --out ./results/offline_eval.csv

ğŸ” å¸¸è§é—®é¢˜ï¼ˆFAQï¼‰

Q1. faiss å¯¼å…¥æŠ¥ NumPy 2.x å…¼å®¹é—®é¢˜ï¼Ÿ
Aï¼šä½¿ç”¨ conda-forge å®‰è£… faiss-cpuï¼Œå¹¶ç¡®ä¿ numpy<2ï¼š

conda install -c conda-forge "faiss-cpu>=1.7.4,<2.0.0" "numpy<2" -y


å®‰è£…å¤±è´¥æ—¶å¯å…ˆè·³è¿‡ FAISS æ­¥éª¤ï¼Œè¯„æµ‹ä¼šè‡ªåŠ¨å›é€€åˆ°å…¨åº“ç‚¹ç§¯ï¼ˆæ›´æ…¢ä½†å¯ç”¨ï¼‰ã€‚

Q2. VQ çš„ token éƒ½é›†ä¸­åˆ°ä¸€ä¸ªæ¡¶ï¼Ÿ

ç¡®è®¤è®­ç»ƒ/ç¼–ç ä½¿ç”¨çš„æ˜¯åŒä¸€ codebookï¼ˆ--load æ­£ç¡®ï¼‰ä¸”é‡åŒ–å™¨åœ¨ç›¸åŒ deviceï¼ˆæˆ‘ä»¬å·²ä¿®å¤ .to(device)ï¼‰ã€‚

è®­ç»ƒ --epochs é€‚å½“æé«˜ï¼ˆ5â€“10ï¼‰ï¼Œ--dist-chunk è°ƒå°ï¼ˆ256/512ï¼‰ã€‚

Q3. RQ å€™é€‰å¤ªå°å¯¼è‡´ Recall ä½ï¼Ÿ

ç›®å‰å€’æ’ç”¨â€œç²¾ç¡® code ä¸²â€ã€‚åç»­å¯ä»¥å¼€å¯ Hamming-1 æ‰©å±• æˆ– åˆ†å±‚å¹¶é›†æ‰©å¤§å€™é€‰ï¼ˆTODOï¼‰ã€‚

ğŸ“Š ç»“æœå¤ç°ä¸å¯¹æ¯”

ä»¥ ç›¸è¿‘ç é•¿å¯¹æ¯”ï¼š

RQ 4Ã—256 â‰ˆ 32bit

VQ K=4096 â‰ˆ 12bitï¼ˆå¯å†è·‘ 8192/32768 åšæ›´å…¬å¹³æ¯”è¾ƒï¼‰

æŒ‡æ ‡ï¼šRecall@Kã€NDCG@Kã€avg_cand_sizeã€cold_start_skippedã€‚

ğŸ”– License

æœ¬ä»“åº“ä»£ç é‡‡ç”¨ MIT Licenseã€‚
ä½¿ç”¨çš„å…¬å¼€æ•°æ®ï¼ˆå¦‚ Amazon Reviews 2023ï¼‰è¯·éµå®ˆå…¶åŸå§‹è®¸å¯ä¸ä½¿ç”¨æ¡æ¬¾ã€‚

ğŸ™ Acknowledgements

McAuley Lab â€” Amazon Reviews 2023

VQ-VAE / RQ-VAE ç›¸å…³å·¥ä½œä¸ç¤¾åŒºå®ç°

FAISS


---

éœ€è¦æˆ‘å†å¸®ä½ è¡¥ä¸€ä¸ª `scripts/run_all.sh`ï¼ˆä¸€é”®ä»é¢„å¤„ç†åˆ°è¯„æµ‹ï¼‰æˆ– GitHub Actionsï¼ˆlint/åŸºç¡€æ£€æŸ¥ï¼‰çš„æ¨¡æ¿å—ï¼Ÿæˆ‘å¯ä»¥ç›´æ¥æŒ‰ä½ å½“å‰ç›®å½•ç»“æ„äº§å‡ºã€‚
::contentReference[oaicite:0]{index=0}